{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MillenniumAI performance comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set executable paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "import torch\n",
    "import subprocess\n",
    "from typing import Tuple, List, Dict\n",
    "import socket\n",
    "import pickle\n",
    "import time\n",
    "import tracemalloc\n",
    "\n",
    "# Necessary to import from sibling directory\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "\n",
    "from pymdb import (\n",
    "    MDBClient,\n",
    "    TrainGraphLoader,\n",
    "    EvalGraphLoader,\n",
    "    SamplingGraphLoader,\n",
    "    Sampler,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to MillenniumDB/MillenniumAI executables\n",
    "SERVER_PYMDB_PATH = \"/home/mdbai/MillenniumDB-Dev/build/Release/bin/server_pymdb\"\n",
    "CREATE_DB_PATH = \"/home/mdbai/MillenniumDB-Dev/build/Release/bin/create_db\"\n",
    "GENERATION_BASE_PATH = \"/home/mdbai/PyMDB/examples/generated\"\n",
    "\n",
    "if not os.path.exists(SERVER_PYMDB_PATH):\n",
    "    raise Exception(\n",
    "        \"SERVER_PYMDB_PATH is not set to the correct path. \"\n",
    "        \"Please set it to the path of the MillenniumDB server_pymdb executable.\"\n",
    "    )\n",
    "\n",
    "if not os.path.exists(CREATE_DB_PATH):\n",
    "    raise Exception(\n",
    "        \"CREATE_DB_PATH is not set to the correct path. \"\n",
    "        \"Please set it to the path of the MillenniumDB create_db executable.\"\n",
    "    )\n",
    "\n",
    "# Port to run MillenniumDB server on\n",
    "SERVER_PORT = 8080"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define performance test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_node_feat(num_nodes, num_node_feat):\n",
    "    print(\"  Generating node features...\")\n",
    "    return torch.zeros((num_nodes, num_node_feat), dtype=torch.float32)\n",
    "        \n",
    "def gen_edge(num_nodes, num_edges):\n",
    "    print(\"  Generating graph edges...\")    \n",
    "    return torch.randint(0, num_nodes - 1, (2, num_edges))\n",
    "\n",
    "# Generate graphs in multiple formats. Returns the necessary data of each one\n",
    "def generate_graphs(\n",
    "    num_nodes: int,\n",
    "    num_edges: int,\n",
    "    num_node_feat: int,\n",
    ") -> Tuple[Data, str]:\n",
    "    graph_name = f\"N{num_nodes}_E{num_edges}_F{num_node_feat}\"\n",
    "    \n",
    "    # In-memory graph\n",
    "    pickle_path = f\"{GENERATION_BASE_PATH}/{graph_name}.pkl\"\n",
    "    if os.path.exists(pickle_path):\n",
    "        # Load a graph from an existing pickle\n",
    "        print(\"  Pickle graph dump already exists. Loading file...\")\n",
    "        graph = pickle.load(open(pickle_path, \"rb\"))\n",
    "    else:\n",
    "        # Generate a new graph and dump to a pickle\n",
    "        graph = Data(\n",
    "            num_nodes=num_nodes,\n",
    "            node_feat=gen_node_feat(num_nodes, num_node_feat),\n",
    "            edge_index=gen_edge(num_nodes, num_edges)\n",
    "        )\n",
    "        print(\"  Writing the generated graph to a pickle...\")\n",
    "        pickle.dump(graph, open(pickle_path, \"wb\"))\n",
    "\n",
    "    # On-disk MillenniumDB graph\n",
    "    mdb_dump_path = f\"{GENERATION_BASE_PATH}/{graph_name}.milldb\"\n",
    "    if os.path.exists(mdb_dump_path):\n",
    "        # Skip MDB dump creation\n",
    "        print(\"  MillenniumDB's graph dump already exists. Skipping dump creation...\")\n",
    "    else:\n",
    "        with open(mdb_dump_path, \"w\") as f:\n",
    "            for idx in range(graph.num_nodes):\n",
    "                f.write(f\"N{idx} feat:{graph.node_feat[idx].tolist()}\\n\")\n",
    "            for edge in graph.edge_index.T:\n",
    "                f.write(f\"N{edge[0]}->N{edge[1]} :T\\n\")\n",
    "\n",
    "    return graph, mdb_dump_path\n",
    "\n",
    "\n",
    "# Create a MillenniumDB database from a file in the current directory and return its path\n",
    "def create_db(mdb_dump_path: str) -> str:\n",
    "    dest_path = mdb_dump_path.replace(\".milldb\", \"\")\n",
    "    \n",
    "    if os.path.isdir(dest_path):\n",
    "        print(\"  MillenniumDB's database already exists. Skipping database creation...\")\n",
    "    else:\n",
    "        print(\"  Creating MillenniumDB's database...\")\n",
    "        result = subprocess.run(\n",
    "            [CREATE_DB_PATH, mdb_dump_path, dest_path],\n",
    "            stdout=subprocess.DEVNULL,\n",
    "            stderr=subprocess.PIPE,\n",
    "        )\n",
    "        if result.returncode != 0:\n",
    "            raise RuntimeError(f\"create_db: {result.stderr.decode('utf-8')}\")\n",
    "    return dest_path\n",
    "\n",
    "\n",
    "# Start a MillenniumDB server for a given database directory\n",
    "def start_server(db_path: str):\n",
    "    process = subprocess.Popen(\n",
    "        [SERVER_PYMDB_PATH, db_path, \"-p\", str(SERVER_PORT)],\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.PIPE,\n",
    "    )\n",
    "\n",
    "    # Wait for server to listen to port\n",
    "    while socket.socket().connect_ex((\"localhost\", SERVER_PORT)) != 0:\n",
    "        time.sleep(0.5)\n",
    "\n",
    "    return process\n",
    "\n",
    "\n",
    "# Kill a MillenniumDB server process and return its exit code\n",
    "def kill_server(process) -> int:\n",
    "    process.kill()\n",
    "    return process.wait()\n",
    "\n",
    "# Clear both buffer/cache and swap of the OS\n",
    "def clear_os():\n",
    "    os.system(\"sudo sync && echo 3 | sudo tee /proc/sys/vm/drop_caches > /dev/null\")\n",
    "    os.system(\"sudo swapoff -a && sudo swapon -a\")\n",
    "\n",
    "# Get the a in-memory graph memory estimation in MB (node_features + edge_index)\n",
    "def graph_size(graph):\n",
    "    return (graph.node_feat.numel() * 4 + graph.edge_index.numel() * 8) / 1e6\n",
    "\n",
    "# Run performance tests for a list of instances and a list of batch sizes\n",
    "def run_performance_tests(instances: List[Dict], batch_sizes: List[int]):\n",
    "    if not os.path.exists(GENERATION_BASE_PATH):\n",
    "        os.makedirs(GENERATION_BASE_PATH)\n",
    "\n",
    "    plot_data = dict()\n",
    "\n",
    "    for instance in instances:\n",
    "        print(f\"Running for instance: {instance}...\")\n",
    "        # Generate graphs\n",
    "        graph, mdb_dump_path = generate_graphs(**instance)\n",
    "        db_path = create_db(mdb_dump_path)\n",
    "\n",
    "        plot_data[db_path] = {\n",
    "            \"time_mem\": list(), \n",
    "            \"time_mdb\": list(),\n",
    "            \"mempeak_mem\": list(),\n",
    "            \"mempeak_mdb\": list(),\n",
    "            \"batch_size\": list(),\n",
    "        }\n",
    "        for batch_size in batch_sizes:\n",
    "            print(f\"    Running for batch size: {batch_size}...\")\n",
    "            plot_data[db_path][\"batch_size\"].append(batch_size)\n",
    "            \n",
    "            \n",
    "            # 1. In-memory graph\n",
    "            clear_os()\n",
    "            tracemalloc.start()\n",
    "            t0_mem = time.perf_counter_ns()\n",
    "            for batch in NeighborLoader(\n",
    "                graph, num_neighbors=[5, 5], batch_size=batch_size\n",
    "            ):\n",
    "                # Here the batch would be passed to a model\n",
    "                pass\n",
    "            plot_data[db_path][\"time_mem\"].append((time.perf_counter_ns() - t0_mem) / 1e9)\n",
    "            _, peak = tracemalloc.get_traced_memory()\n",
    "            plot_data[db_path][\"mempeak_mem\"].append((peak / 1e6) + graph_size(graph))\n",
    "            tracemalloc.stop()\n",
    "            \n",
    "            \n",
    "            # 2. MillenniumDB graph\n",
    "            clear_os()\n",
    "            tracemalloc.start()\n",
    "            server_process = start_server(db_path)\n",
    "            with MDBClient(\"localhost\", SERVER_PORT) as client:\n",
    "                t0_mdb = time.perf_counter_ns()\n",
    "                for batch in EvalGraphLoader(\n",
    "                    client, num_neighbors=[5, 5], batch_size=batch_size\n",
    "                ):\n",
    "                    # Here the batch would be passed to a model\n",
    "                    pass\n",
    "                plot_data[db_path][\"time_mdb\"].append((time.perf_counter_ns() - t0_mdb) / 1e9)\n",
    "                _, peak = tracemalloc.get_traced_memory()\n",
    "                plot_data[db_path][\"mempeak_mdb\"].append(peak / 1e6)\n",
    "                tracemalloc.stop()\n",
    "            kill_server(server_process)\n",
    "\n",
    "    return plot_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run performance tests for instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for instance: {'num_nodes': 100000000, 'num_edges': 1000000000, 'num_node_feat': 4}...\n",
      "  Generating randomized node features...\n",
      "  Generating randomized graph edges...\n",
      "  Writing the generated graph to a pickle...\n"
     ]
    }
   ],
   "source": [
    "instances = [\n",
    "    {\"num_nodes\": 100_000_000, \"num_edges\": 1_000_000_000, \"num_node_feat\": 4},\n",
    "    #{\"num_nodes\": 1_000, \"num_edges\": 10_000, \"num_node_feat\": 4},\n",
    "]\n",
    "args = {\n",
    "    \"instances\": instances, \n",
    "    \"batch_sizes\": [10_000, 100_000]\n",
    "}\n",
    "\n",
    "plot_data = run_performance_tests(**args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(x: List, y1: List, y2: List, x_label: str, y_label: str, title: str):\n",
    "    plt.plot(x, y1, label=\"In-memory\")\n",
    "    plt.plot(x, y2, label=\"MillenniumDB\")\n",
    "    \n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(plot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time vs Batch Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Compare time over graph size\n",
    "for db_path, data in plot_data.items():\n",
    "    plot_comparison(\n",
    "        data[\"batch_size\"],\n",
    "        data[\"time_mem\"],\n",
    "        data[\"time_mdb\"],\n",
    "        \"Batch size\",\n",
    "        \"Time (s)\",\n",
    "        f\"Graph: {os.path.basename(db_path)}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Peak memory usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare time over graph size\n",
    "for db_path, data in plot_data.items():\n",
    "    plot_comparison(\n",
    "        data[\"batch_size\"],\n",
    "        data[\"mempeak_mem\"],\n",
    "        data[\"mempeak_mdb\"],\n",
    "        \"Batch size\",\n",
    "        \"Peak memory usage (MB)\",\n",
    "        f\"Graph: {os.path.basename(db_path)}\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cold storage size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
